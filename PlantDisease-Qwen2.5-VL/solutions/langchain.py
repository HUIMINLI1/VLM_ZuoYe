"""
LangChain-based Prototype for Plant Disease Diagnosis
ç”¨äºéªŒè¯ RAG + å¤§æ¨¡å‹åœ¨æ¤ç‰©ç—…å®³è¯Šæ–­ä¸­çš„å®éªŒæ€§å®ç°
"""

import sys
import os
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.prompts.prompt import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils import CONFIG_AND_SETTINGS
from engine.model import Qwen
from retrieval.RAGHandler_langchain import load_file, FAISSWrapper


# ==================================================
# åˆå§‹åŒ– LangChain ç—…å®³è¯Šæ–­ Agent
# ==================================================
def initialize_agent():
    """
    æ„å»ºåŸºäº LangChain çš„æ¤ç‰©ç—…å®³è¯Šæ–­ Agentï¼ˆå®éªŒåŸå‹ï¼‰
    """

    # ===== åŠ è½½å†œä¸šçŸ¥è¯†åº“ =====
    knowledge_files = [
        CONFIG_AND_SETTINGS.get("disease_knowledge_filepath", ""),
        CONFIG_AND_SETTINGS.get("treatment_knowledge_filepath", "")
    ]

    # ===== Embedding è®¾ç½® =====
    embedding_model_dict = {
        "text2vec": "shibing624/text2vec-base-chinese",
        "gte-zh": "thenlper/gte-large-zh",
        "gte": "thenlper/gte-large",
    }
    EMBEDDING_MODEL = "gte-zh"
    EMBEDDING_DEVICE = "cuda"
    VECTOR_SEARCH_TOP_K = 5

    # ===== Prompt è®¾è®¡ï¼ˆç—…å®³è¯Šæ–­ä¸“ç”¨ï¼‰=====
    PROMPT_TEMPLATE = """
ã€å‚è€ƒå†œä¸šçŸ¥è¯†ã€‘
{context}

ã€è¾“å…¥ä¿¡æ¯ã€‘
{question}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯å®Œæˆæ¤ç‰©ç—…å®³è¯Šæ–­åˆ†æï¼Œè¦æ±‚ï¼š
1. æ€»ç»“å›¾åƒä¸­å¯è§‚å¯Ÿåˆ°çš„ä¸»è¦ç—‡çŠ¶ï¼›
2. æ¨æ–­æœ€å¯èƒ½çš„ç—…å®³ç±»å‹ï¼Œå¹¶è¯´æ˜ä¾æ®ï¼›
3. åˆ†æå¯èƒ½çš„è¯±å‘å› ç´ ï¼ˆç¯å¢ƒã€ç”Ÿè‚²æœŸç­‰ï¼‰ï¼›
4. ç»™å‡ºç—…å®³ä¸¥é‡ç¨‹åº¦åˆ¤æ–­ï¼ˆè½» / ä¸­ / é‡ï¼‰ï¼›
5. æä¾›ç§‘å­¦ã€å¯æ“ä½œçš„é˜²æ²»å»ºè®®ã€‚

è¯·ä½¿ç”¨ä¸“ä¸šã€ç®€æ´ã€ç»“æ„åŒ–çš„è¯­è¨€ä½œç­”ã€‚
"""

    # ===== åˆå§‹åŒ–æ¨¡å‹ä¸å‘é‡åº“ =====
    llm = Qwen()
    embeddings = HuggingFaceEmbeddings(
        model_name=embedding_model_dict[EMBEDDING_MODEL],
        model_kwargs={"device": EMBEDDING_DEVICE}
    )

    docs = []
    for filepath in knowledge_files:
        if filepath:
            docs.extend(load_file(filepath, check_file=True))

    docsearch = FAISSWrapper.from_documents(docs, embeddings)

    prompt = PromptTemplate(
        template=PROMPT_TEMPLATE,
        input_variables=["context", "question"]
    )

    def format_docs(docs):
        return "\n".join(doc.page_content for doc in docs)

    # ===== æ„å»º LCEL Chain =====
    qa_chain = (
        {
            "context": docsearch.as_retriever(
                search_kwargs={"k": VECTOR_SEARCH_TOP_K}
            ) | format_docs,
            "question": RunnablePassthrough(),
        }
        | prompt
        | llm
        | StrOutputParser()
    )

    return qa_chain


# ==================================================
# CLI è°ƒè¯•å…¥å£ï¼ˆä»…ç”¨äºå®éªŒï¼‰
# ==================================================
if __name__ == "__main__":
    print("ğŸŒ± Plant Disease Diagnosis Agent Initialized")

    agent = initialize_agent()

    while True:
        print("\n------ Plant Diagnosis Agent Standby ------")

        user_input = input("è¯·è¾“å…¥ç—‡çŠ¶æè¿° / ç—…å®³é—®é¢˜ï¼ˆ--q é€€å‡ºï¼‰ï¼š\n")
        if not user_input:
            user_input = "å¶ç‰‡å‡ºç°è¤è‰²ä¸è§„åˆ™æ–‘ç‚¹ï¼Œè¾¹ç¼˜å‘é»„ï¼Œè¿‘æœŸè¿ç»­é˜´é›¨ã€‚"
            print(f"[ç¤ºä¾‹è¾“å…¥] {user_input}")

        if "--q" in user_input.lower():
            print("ğŸ‘‹ è¯Šæ–­ Agent å·²é€€å‡º")
            break

        print("\n------ æ­£åœ¨è¿›è¡Œç—…å®³è¯Šæ–­åˆ†æ... ------\n")
        try:
            result = agent.invoke(user_input)
            print(result)
        except KeyboardInterrupt:
            print("âš ï¸ ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            print("âŒ è¯Šæ–­å¤±è´¥ï¼š", e)
